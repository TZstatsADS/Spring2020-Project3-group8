---
title: "Main"
author: "Jiancong Shen, Vikki Sui, Jinxu Xiang, Ruiqi Xie, Wenjie Xie"
output:
  html_document:
    df_print: paged
---

## Abstract

This document mainly describes an improved way of expression recognition algorithm. This method reduces the calculation time and improves the classification accuracy by pre-transforming data, extracting efficient features (base on points and images). The goal is to select the best model by comparing the classification results of different classifiers under different features.

###  Computer configuration

System: Microsoft Windows 10 x64

CPU: Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz(3600 MHz)

GPU: NVIDIA GeForce RTX 2070 SUPER (8192 MB)

RAM: 16.00 GB (2400 MHz)

### Final result

|       | test accuracy | model training time | all training time | test prediction time | all prediction time | 
| ------ | ------ | ------ | ------ | ------ | ------ | 
| gbm_baseline | 45.6% | 1960s | 1961s | 13.3s | 13.4s |
| gbm_improved | 46.2% | 42.9s | 67.2s | 0.03s | 5.92s | 
| gbm_colored | 48.1% | 45.2s | 188s | 0.04s | 68.6s |
| svm_improved | 57.1% | 2.39s | 26.7s | 0.20s | 6.09s |
| svm_colored | 60.5% | 2.38s | 146s | 0.20s | 38.8s |
| xgb_improved | 52.9% | 45.2s | 67.2s | 0.06s | 5.95s |
| xgb_colored | 55.4% | 31.7s | 175s | 0.06s | 38.6s |

Based on the fact that the total training time is the sum of model training time, the feature extraction time, and the data processing time, we have the formula below:

all training time = data preprocessing time + feature extraction time + model training time

The accuracy and time shown in the table above are from a certain measurement and may not exactly match the results shown in the PDF document.

The improved feature contains 129 data extracted from 78 points' position. The color feature contains all improved feature and and 10 other feature which extracts from points and images. The dimension of color feature is 139.

We extract color feature and use the svm classifier as our improved model. Since there is no other results affect our judgment of in-class tests. We predict the final accuracy of in-class test to be 58%.

```{r message=FALSE}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
if(!require("R.matlab")){
  install.packages("R.matlab")
}
if(!require("readxl")){
  install.packages("readxl")
}
if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("readxl")){
  install.packages("readxl")
}
if(!require("ggplot2")){
  install.packages("ggplot2")
}
if(!require("caret")){
  install.packages("caret")
}
if(!require("gbm")){
  install.packages("gbm")
}
if(!require("e1071")){
  install.packages("e1071")
}
if(!require("geometry")){
  install.packages("geometry")
}
if(!require("mlogit")){
  install.packages("mlogit")
}
if(!require("tidyverse")){
  install.packages("tidyverse")
}
if(!require("xgboost")){
  install.packages("xgboost")
}

library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
library(e1071)
library(geometry)
library(mlogit)
library(tidyverse)
library(xgboost)  
```

## Step 0 set work directories

```{r , eval=FALSE}
set.seed(1)
setwd("C:/course/5243 Applied Data Science/Project/Spring2020-Project3-group8/doc")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located. 
# use relative path for reproducibility
```

Provide directories for training images. Training images and training fiducial points will be in different subfolders. 

```{r}
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 
```


## Step 1: set up controls for evaluation experiments.

In this chunk, we have a set of controls for the evaluation experiments. 

+ (T/F) process for baseline
+ (T/F) process for data set
+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) process features for training and test set
+ (T/F) process model of training data

```{r}
run.baseline = TRUE # run baseline feature, slow!

run.dataprocess.fiducial_pt_list = FALSE # save fiducial_pt_list
run.dataprocess.all_points = FALSE # save all_points, new data after rotate zoom and move
run.dataprocess.ave_points = FALSE # save ave_points, average data of 22 emotions
run.dataprocess.diff_points = FALSE # save diff, distance of each point to its mean

run.cv = FALSE # run cross-validation on the training set
K = 5  # number of CV folds
run.feature.train = TRUE # process features for training set
run.feature.test = TRUE # process features for test set

run.train.gbm = TRUE # run gbm training model
run.train.svm = TRUE # run svm training model
run.train.xgb = TRUE # run xgb training model
```

The cross-validation method takes too much time, and the model we choose does not need it. Although it works well, we did not run it in this document.

## Step 2: import data and train-test split 

This time we did not use a random 20% photos as the test set, but instead randomized all the pictures of 20% of the people as the test set. Because when we face the problem of facial expression recognition, there is a high probability we encounter strangers. So the expectation of this selection method is closer to the real classification accuracy.

However, we only have 2500 pictures and 230 people, which is not enough for accurate training. So when we randomly select 20% of the people, it is likely that there is too little training for a certain expression in the training set. This may increase the variance of classification accuracy.

This effect is limited to the tests in this document. The tests in the classroom will use all 2,500 training sets, the expectations and variances mentioned above have nothing to do with it.

```{r}
#train-test split
info <- read.csv(train_label_path)
n <- length(info$identity %>% unique())

#take 80% of the observations as the train set
n_train <- round(n*(4/5), 0)
train_identity = sample(info$identity %>% unique(), n_train, replace = F)
train_idx <- which(info$identity %in% train_identity)
test_idx <- setdiff(info$Index,train_idx)
train_idx <- sample(train_idx, length(train_idx), replace = F)
```

Fiducial points are stored in matlab format. In this step, we read them and store them in a list.

```{r}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
if(run.dataprocess.fiducial_pt_list){
  
  n_files <- length(list.files(train_image_dir))
  readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
  }
  
  #load fiducial points
  fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
  save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
}
```

```{r}
#function to rotate, translate, zoom the fiducial points to standardize all the points
#take the middle height of two eyes and the height of nose center to standardize this distance to be 170

#input: indices, train_dir, fiducial_pt_list, single, double
#output: the fiducial points after all the trasformation
if(run.dataprocess.all_points){
  
  source("../lib/change_images.R")
  load("../output/fiducial_pt_list.RData")
  
  single = c(35,36,37,38,44,52,56,59,62)  #points without a match, i.e, points on the axis of symmetry
  double = data.frame(
    x1 = c(1,2,3,4,5,6,7,8,9,19,20,21,22,23,24,25,26,39,40,41,42,43,50,51,57,58,63),
    x2 = c(10,15,14,13,12,11,18,17,16,31,30,29,28,27,34,33,32,49,48,47,46,45,54,53,55,60,61))
  #points that matches each other on both sides of the face
  
  indices = 1:2500
  
  tm.run.all_points = system.time(all_points <- change_points(indices, train_dir, fiducial_pt_list, single, double))
  
  all_points = map(all_points, as.matrix)
  
  save(all_points, file = "../output/all_points.RData")
}
```

```{r}
#data manipulation to find the average points of each emotion, in order to find more detailed differences of each emotion
#input: all_points
#output: ave_points
if(run.dataprocess.ave_points){
  
  load("../output/all_points.RData")
  
  emo_idx = map(1:22, ~info$emotion_idx == .x)
  group_points = map(emo_idx, ~all_points[.x])
  ave_points = NULL
  for (i in 1:length(group_points)){
    mean = matrix(rep(0,78*2), nc = 2)
    l = length(group_points[[i]])
    for(j in 1:l){
      group_points[[i]][[j]]
      mean = mean + group_points[[i]][[j]]/l
    }
    ave_points = c(ave_points, list(mean))
  }
  save(ave_points, file="../output/ave_points.Rdata")
}
```

```{r}
if(run.dataprocess.diff_points){
  
  load("../output/all_points.RData")
  load("../output/ave_points.RData")
  
  #functions to find the difference on x-aixs and y-axis of each point to corresponding points of the 22 average points of different emotions
  #input: emo_index, all_points
  #output: diff
  get_diff <- function(emo_index, train= all_points){
    group <- info %>% filter(emotion_idx == emo_index)
    idx <- group$Index
    points <- train[idx]
    dfmean <- ave_points[[emo_index]]
    diff <- map(points, function(x){x-dfmean})
    return (diff)
  }
  diff_points <- list()
  
  for (i in 1:22){
    diff_points <- c(diff_points, get_diff(i, all_points))
  }
  
  #find the the distance of each point to the corresponding points of the 22 average points of different emotions
  #output: distance
  distance <- map(diff_points, function(x){x[,1]^2+x[,2]^2})
  distance = map(1:78, function(y) map(distance, ~.x[y]) %>% unlist)
  
  save(diff_points, file="../output/diff_points.Rdata")
  save(distance, file="../output/distance.Rdata")
}
load("../output/diff_points.Rdata")
load("../output/distance.Rdata")
```


## Step 3: construct features and responses

+ The follow plots show how pairwise distance between fiducial points can work as feature for facial emotion recognition.

  + In the first column, 78 fiducials points of each emotion are marked in order. 
  + In the second column distributions of vertical distance between right pupil(1) and  right brow peak(21) are shown in  histograms. For example, the distance of an angry face tends to be shorter than that of a surprised face.
  + The third column is the distributions of vertical distances between right mouth corner(50)
and the midpoint of the upper lip(52).  For example, the distance of an happy face tends to be shorter than that of a sad face.

![Figure1](../figs/feature_visualization.jpg)

`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features and responses that are required by all the models you are going to evaluate later. 
  
  + `feature.R`
  + Input: list of images or fiducial point
  + Output: an RData file that contains extracted features and corresponding responses

```{r}
source("../lib/feature_baseline.R")
source("../lib/feature.R")
load("../output/all_points.RData")

#get the time required for taking the features of train set and test set using the original feature function which is simply taking the distance of each two points
if(run.baseline){
  tm_feature_train_baseline <- NA
  if(run.feature.train){
    tm_feature_train_baseline <- system.time(dat_train_baseline <- feature_baseline(fiducial_pt_list, train_idx))
    save(dat_train_baseline, file="../output/feature_train_baseline.RData")
  }
  
  tm_feature_test_baseline <- NA
  if(run.feature.test){
    tm_feature_test_baseline <- system.time(dat_test_baseline <- feature_baseline(fiducial_pt_list, test_idx))
    save(dat_test_baseline, file="../output/feature_test_baseline.RData")
  }
}

#time required for taking the features of train set using the updated feature function with and without the color feature
tm_feature_train <- NA
tm_feature_train_color <- NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx, image_file = "../data/train_set/images/", all_points, colorfeature = FALSE))
  save(dat_train, file="../output/feature_train.RData")
  tm_feature_train_color <- system.time(dat_train_color <- feature(fiducial_pt_list, train_idx, image_file = "../data/train_set/images/", all_points, colorfeature = TRUE))
  save(dat_train_color, file="../output/feature_train_color.RData")
}

#time required for taking the features of test set using the updated feature function with and without the color feature
tm_feature_test <- NA
tm_feature_test_color <- NA
if(run.feature.test){
  tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx, image_file = "../data/train_set/images/", all_points, colorfeature = FALSE))
  save(dat_test, file="../output/feature_test.RData")
  tm_feature_test_color <- system.time(dat_test_color <- feature(fiducial_pt_list, test_idx, image_file = "../data/train_set/images/", all_points, colorfeature = TRUE))
  save(dat_test_color, file="../output/feature_test_color.RData")
}

```

## Step 4: Train a classification model with training features and responses
Call the train model and test model from library. 

`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. 

+ `train.R`
  + Input: a data frame containing features and labels and a parameter list.
  + Output:a trained model
+ `test.R`
  + Input: the fitted classification model using training data and processed features from testing images 
  + Input: an R object that contains a trained classifier.
  + Output: training model specification

+ In this Starter Code, we use KNN to do classification. 

### 1.Baseline model with dist feature in GBM

```{r}
#use the baseline features to train the gbm model, get the model called gbm_model_baseline and the time used called tm.gbm.train_baseline
#save the output model into the output
if(run.baseline){
  load("../output/feature_train_baseline.RData")
  if(run.train.gbm){
    source("../lib/train_gbm.R")
    gbm_result_train_baseline = gbm_train(dat_train_baseline, n.trees = 200, bag.fraction = 0.8, shrinkage = 0.1, cv.folds = 3)
    gbm_model_baseline = gbm_result_train_baseline[[1]]
    tm.gbm.train_baseline = gbm_result_train_baseline[[2]]
    save(gbm_model_baseline, file="../output/gbm_model_baseline.RData")
  }
}
```

### 2.Improved feature in GBM

```{r}
#use the improved features to train the gbm model, get the model called gbm_model and the time used called tm.gbm.train
#save the output model into the output
if(run.train.gbm){
  source("../lib/train_gbm.R")
  load("../output/feature_train.RData")
  
  gbm_result_train = gbm_train(dat_train, n.trees = 200, bag.fraction = 0.8, shrinkage = 0.1, cv.folds = 3)
  gbm_model = gbm_result_train[[1]]
  tm.gbm.train = gbm_result_train[[2]]
  save(gbm_model, file="../output/gbm_model.RData")
}
```

### 3.Improved feature in SVM

```{r}
#use the improved features to train the svm model, get the model called svm_model and the timeused called tm.svm.train
#save the output model into the output
if(run.train.svm){
  source("../lib/train_SVM.R")
  load("../output/feature_train.RData")
  
  svm_result_train = svm_train(dat_train, kernel = 'poly', degree = 1, gamma = 0.008)
  svm_model = svm_result_train[[1]]
  tm.svm.train = svm_result_train[[2]]
  save(svm_model, file="../output/svm_model.RData")
}
```

### 4.Improved feature in XGB

```{r}
#use cross validation to find the best parameter for the xgb model
if(run.cv & run.train.xgb){
  source("../lib/xgb_tune.R")
  load("../output/feature_train.RData")
  
  depth = c(5,10,15)
  child = c(3,5,10)
  xgb_result_cv = xgb_tune(dat_train, depth, child, K)
  xgb_err = xgb_result_cv[[1]]
  tm.xgb.cv = xgb_result_cv[[2]]
  xgb_err_tune = xgb_err[[1]] %>% as.data.frame()
  xgb_best_par = xgb_err[[2]] %>% as.data.frame()
}
```

```{r}
if(run.cv & run.train.xgb){
  colnames(xgb_err_tune) = c(3,5,10)
  xgb_err_tune = gather(xgb_err_tune, key = "min_child")
  xgb_err_tune$depth = rep(c(5,10,15),3)
  xgb_err_tune
  ggplot(xgb_err_tune, mapping = aes(x=min_child, y=depth, fill=value))+
    geom_tile()
}
```

```{r}
#fit the xgb model with the best parameter if we use cross validation and with default if we do not use cross validation, and save the xgb_model into the output folder
if(run.train.xgb){
  source("../lib/xgb_train.R")
  load("../output/feature_train.RData")
  
  if(run.cv)
    xgb_result = xgb_train(dat_train, par = best_par_xgb)
  else
    xgb_result = xgb_train(dat_train)
  xgb_model = xgb_result[[1]]
  tm.xgb.train = xgb_result[[2]]
  save(xgb_model, file="../output/xgb_model.RData")
}

```

### 5.Improved feature with color in GBM

```{r}
#use the features with colors to train the gbm model called gbm_model_color, and save the model into output folder
if(run.train.gbm){
  source("../lib/train_gbm.R")
  load("../output/feature_train_color.RData")
  
  gbm_result_train_color = gbm_train(dat_train_color, n.trees = 200, bag.fraction = 0.8, shrinkage = 0.1, cv.folds = 3)
  gbm_model_color = gbm_result_train_color[[1]]
  tm.gbm.train_color = gbm_result_train_color[[2]]
  save(gbm_model_color, file="../output/gbm_model_color.RData")
}
```

### 6.Improved feature with color in SVM

```{r}
#use the features with colors to train the svm model called svm_model_color and save the model into output folder
if(run.train.svm){
  source("../lib/train_SVM.R")
  load("../output/feature_train_color.RData")
  
  svm_result_train_color = svm_train(dat_train_color, kernel = 'poly', degree = 1, gamma = 0.008)
  svm_model_color = svm_result_train_color[[1]]
  tm.svm.train_color = svm_result_train_color[[2]]
  save(svm_model_color, file="../output/svm_model_color.RData")
}
```

### 7.Improved feature with color in XGB

```{r}
#We can choose to use cross validation or not. If yes, we will need to run the two chunks below and get the best parameters, if not, we can skip the cross validation steps
if(run.cv & run.train.xgb){
  source("../lib/xgb_tune.R")
  load("../output/feature_train_color.RData")
  
  depth = c(5,10,15)
  child = c(3,5,10)
  xgb_result_cv_color = xgb_tune(dat_train_color, depth, child, K)
  xgb_err_color = xgb_result_cv_color[[1]]
  tm.xgb.cv_color = xgb_result_cv_color[[2]]
  xgb_err_tune_color = xgb_err_color[[1]] %>% as.data.frame()
  xgb_best_par_color = xgb_err_color[[2]] %>% as.data.frame()
}
```

```{r}
if(run.cv & run.train.xgb){
  colnames(xgb_err_tune_color) = c(3,5,10)
  xgb_err_tune_color = gather(xgb_err_tune_color, key = "min_child")
  xgb_err_tune_color$depth = rep(c(5,10,15),3)
  xgb_err_tune_color
  ggplot(xgb_err_tune_color, mapping = aes(x=min_child, y=depth, fill=value))+
    geom_tile()
}
```

```{r}
#use the features with colors to train the xgb model called xgb_model_color and save the model into the output folder
if(run.train.xgb){
  source("../lib/xgb_train.R")
  load("../output/feature_train_color.RData")
  
  if(run.cv)
    xgb_result_color = xgb_train(dat_train_color, par = best_par_xgb)
  else
    xgb_result_color = xgb_train(dat_train_color)
  xgb_model_color = xgb_result_color[[1]]
  tm.xgb.train_color = xgb_result_color[[2]]
  save(svm_model, file="../output/xgb_model_color.RData")
}

```


## Step 5: Run test on test images

### 1.Baseline model with dist feature in GBM

```{r}
#prediction of the gbm model with only baseline features
if(run.baseline){
  source("../lib/test_gbm.R")
  load("../output/gbm_model_baseline.RData")
  load("../output/feature_test_baseline.RData")
  
  gbm_result_test_baseline = gbm_test(gbm_model_baseline, dat_test_baseline)
  gbm_pred_baseline = gbm_result_test_baseline[[1]]
  tm.gbm.test_baseline = gbm_result_test_baseline[[2]]
  gbm_pred_class_baseline = apply(gbm_pred_baseline, 1, which.max)
}
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(gbm_pred_class_baseline), dat_test$emotion_idx)
```

```{r}
#accuracy of the above gbm model
if(run.baseline){
  gbm_accuracy_test_baseline = mean(dat_test_baseline$emotion_idx == gbm_pred_class_baseline)
  print(paste0("The accuracy for gbm model baseline is: ", gbm_accuracy_test_baseline))
}
```

### 2.Improved feature in GBM

```{r}
#prediction of the gbm model with improved features
source("../lib/test_gbm.R")
load("../output/gbm_model.RData")
load("../output/feature_test.RData")

gbm_result_test = gbm_test(gbm_model, dat_test)
gbm_pred = gbm_result_test[[1]]
tm.gbm.test = gbm_result_test[[2]]
gbm_pred_class = apply(gbm_pred, 1, which.max)
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(gbm_pred_class), dat_test$emotion_idx)
```

```{r}
#get the accuracy of the prediction of gmb model with improved features
gbm_accuracy_test = mean(dat_test$emotion_idx == gbm_pred_class)
print(paste0("The accuracy for gbm model is: ", gbm_accuracy_test))
```

### 3.Improved feature in SVM

```{r}
#prediction of the svm model with improved features
source("../lib/test_SVM.R")
load("../output/svm_model.RData")
load("../output/feature_test.RData")

svm_result_test = svm_test(svm_model, dat_test)
svm_pred_class = svm_result_test[[1]]
tm.svm.test = svm_result_test[[2]]
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(svm_pred_class), dat_test$emotion_idx)
```

```{r}
#get the accuracy of the prediction of the svm model with improved features
svm_accuracy_test = mean(dat_test$emotion_idx == svm_pred_class)
print(paste0("The accuracy for svm model is: ", svm_accuracy_test))
```

### 4.Improved feature in XGB

```{r}
#prediction of the xgb model with improved features
source("../lib/xgb_test.R")
load("../output/xgb_model.RData")
load("../output/feature_test.RData")

xgb_result_test = xgb_test(xgb_model, dat_test[,-ncol(dat_test)])
xgb_pred = xgb_result_test[[1]]
tm.xgb.test = xgb_result_test[[2]]
xgb_pred_class = apply(xgb_pred, 1, which.max)-1
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(xgb_pred_class), dat_test$emotion_idx)
```

```{r}
#get the accuracy of the prediction of the xgb model with improved features
xgb_accuracy_test = mean(dat_test$emotion_idx == xgb_pred_class)
print(paste0("The accuracy for xgb model is: ", xgb_accuracy_test))
```

### 5.Improved feature with color in GBM

```{r}
#prediction of the gbm model with improved features and colors features
source("../lib/test_gbm.R")
load("../output/gbm_model_color.RData")
load("../output/feature_test_color.RData")

gbm_result_test_color = gbm_test(gbm_model_color, dat_test_color)
gbm_pred_color = gbm_result_test_color[[1]]
tm.gbm.test_color = gbm_result_test_color[[2]]
gbm_pred_class_color = apply(gbm_pred_color, 1, which.max)
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(gbm_pred_class_color), dat_test_color$emotion_idx)
```

```{r}
#get the accuracy of the prediction of the gbm model with improved features and color features
gbm_accuracy_test_color = mean(dat_test_color$emotion_idx == gbm_pred_class_color)
print(paste0("The accuracy for gbm model is: ", gbm_accuracy_test_color))
```

### 6.Improved feature with color in SVM

```{r}
#prediction of the svm model with improved features and colors features
source("../lib/test_SVM.R")
load("../output/svm_model_color.RData")
load("../output/feature_test_color.RData")

svm_result_test_color = svm_test(svm_model_color, dat_test_color)
svm_pred_class_color = svm_result_test_color[[1]]
tm.svm.test_color = svm_result_test_color[[2]]
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(svm_pred_class_color), dat_test_color$emotion_idx)
```

```{r}
#get the accuracy of the prediction of the gbm model with improved features and color features
svm_accuracy_test_color = mean(dat_test_color$emotion_idx == svm_pred_class_color)
print(paste0("The accuracy for svm model is: ", svm_accuracy_test_color))
```

### 7.Improved feature with color in XGB

```{r}
#prediction of the xgb model with improved features and colors features
source("../lib/xgb_test.R")
load("../output/xgb_model_color.RData")
load("../output/feature_test_color.RData")

xgb_result_test_color = xgb_test(xgb_model_color, dat_test_color[,-ncol(dat_test_color)])
xgb_pred_color = xgb_result_test_color[[1]]
tm.xgb.test_color = xgb_result_test_color[[2]]
xgb_pred_class_color = apply(xgb_pred_color, 1, which.max)-1
```

```{r}
#get the confusion matrix of the prediction
confusionMatrix(factor(xgb_pred_class_color), dat_test_color$emotion_idx)
```

```{r}
#get the accuracy of the prediction of the gbm model with improved features and color features
xgb_accuracy_test_color = mean(dat_test_color$emotion_idx == xgb_pred_class_color)
print(paste0("The accuracy for xgb model is: ", xgb_accuracy_test_color))
```

### Summarize Accuracy

```{r}
my_theme = theme_light() + 
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) 
```

```{r}
#create a tibble of predict accuracy of each model
if(run.baseline){
  accuracy_test = tibble(gbm_baseline = gbm_accuracy_test_baseline, 
                         gbm_improved = gbm_accuracy_test, 
                         svm_improved = svm_accuracy_test, 
                         xgb_improed = xgb_accuracy_test, 
                         gbm_colored = gbm_accuracy_test_color, 
                         svm_colored = svm_accuracy_test_color, 
                         xgb_colored = xgb_accuracy_test_color)
}else{
  accuracy_test = tibble(gbm_improved = gbm_accuracy_test, 
                         svm_improved = svm_accuracy_test, 
                         xgb_improed  = xgb_accuracy_test, 
                         gbm_colored = gbm_accuracy_test_color, 
                         svm_colored = svm_accuracy_test_color, 
                         xgb_colored = xgb_accuracy_test_color)
}
```

```{r}
 accuracy_test %>% pivot_longer(1:ncol(accuracy_test))%>% 
    ggplot(aes(x = name, fill = name)) +
    geom_bar(aes(weight = value)) + 
    labs(x = 'Classifier', y = 'Accuracy',
         title = 'The Accuracy of Different Classifier under Different Feature') + 
    my_theme
```

### Summarize Running Time

Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 

```{r}
#get a tibble of the running time, tm.train for the training and tm.test for the test
if(run.baseline){
  tm.train = tibble(gbm_baseline = tm.gbm.train_baseline[3], 
                    gbm_improved = tm.gbm.train[3], 
                    svm_improved = tm.svm.train[3], 
                    xgb_improved = tm.xgb.train[3], 
                    gbm_color = tm.gbm.train_color[3], 
                    svm_color = tm.svm.train_color[3], 
                    xgb_color = tm.xgb.train_color[3])
  tm.test= tibble(gbm_baseline = tm.gbm.test_baseline[3], 
                  gbm_improved = tm.gbm.test[3], 
                  svm_improved = tm.svm.test[3], 
                  xgb_improved = tm.xgb.test[3], 
                  gbm_color = tm.gbm.test_color[3], 
                  svm_color = tm.svm.test_color[3], 
                  xgb_color = tm.xgb.test_color[3])
}else{
  tm.train = tibble(gbm_improved = tm.gbm.train[3],
                    svm_improved = tm.svm.train[3], 
                    xgb_improved = tm.xgb.train[3], 
                    gbm_color = tm.gbm.train_color[3], 
                    svm_color = tm.svm.train_color[3],
                    xgb_color = tm.xgb.train_color[3])
  tm.test = tibble(gbm_improved = tm.gbm.test[3], 
                   svm_improved = tm.svm.test[3], 
                   xgb_improved = tm.xgb.test[3], 
                   gbm_color = tm.gbm.test_color[3], 
                   svm_color = tm.svm.test_color[3], 
                   xgb_color = tm.xgb.test_color[3])
}


```

```{r}
#get a tibble of the total running time which used the formula at the begining of the report
#for training, total running time is the sum of data manipulation, extraction of features, and trainig
#for test, the total running time is the sum of data manipulation, extraction of feature, and testing
if(run.baseline){
  tm.train.with = tibble(gbm_baseline = tm.gbm.train_baseline[3]+tm_feature_train_baseline[3],
                    gbm_improved = tm.gbm.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8,
                    svm_improved = tm.svm.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8,
                    xgb_improved = tm.xgb.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8,
                    gbm_color = tm.gbm.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8,
                    svm_color = tm.svm.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8,
                    xgb_color = tm.xgb.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8)
  tm.test.with= tibble(gbm_baseline = tm.gbm.test_baseline[3]+tm_feature_test_baseline[3], 
                  gbm_improved = tm.gbm.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                  svm_improved = tm.svm.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                  xgb_improved = tm.xgb.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                  gbm_color = tm.gbm.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2, 
                  svm_color = tm.svm.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2, 
                  xgb_color = tm.xgb.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2)
}else{
  tm.train.with = tibble(gbm_improved = tm.gbm.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8, 
                    svm_improved = tm.svm.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8, 
                    xgb_improved = tm.xgb.train[3]+tm_feature_train[3]+tm.run.all_points[3]*0.8, 
                    gbm_color = tm.gbm.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8, 
                    svm_color = tm.svm.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8, 
                    xgb_color = tm.xgb.train_color[3]+tm_feature_train_color[3]+tm.run.all_points[3]*0.8)
  tm.test.with = tibble(gbm_improved = tm.gbm.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                   svm_improved = tm.svm.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                   xgb_improved = tm.xgb.test[3]+tm_feature_test[3]+tm.run.all_points[3]*0.2, 
                   gbm_color = tm.gbm.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2, 
                   svm_color = tm.svm.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2, 
                   xgb_color = tm.xgb.test_color[3]+tm_feature_test_color[3]+tm.run.all_points[3]*0.2)
}


```

#### Train time without feature extraction

```{r}
#plot the train time without feature extraction
tm.train %>% pivot_longer(1:ncol(tm.train)) %>% 
  ggplot(aes(x = name, fill = name)) +
  geom_bar(aes(weight = value)) + 
  scale_y_log10() + 
  labs(x = 'Classifier', y = 'Usage Time(s)',
       title = 'Model Training time') + 
  my_theme

```

#### Train time with feature extraction

```{r}
#plot the train time with feature extraction
tm.train.with %>% pivot_longer(1:ncol(tm.train.with)) %>% 
  ggplot(aes(x = name, fill = name)) +
  geom_bar(aes(weight = value)) + 
  scale_y_log10() + 
  labs(x = 'Classifier', y = 'Usage Time(s)',
       title = 'Feature Extraction and Model Training Time') + 
  my_theme

```

#### Test time without feature extraction

```{r}
#plot the test time without feature extraction
tm.test %>% pivot_longer(1:ncol(tm.test)) %>% 
  ggplot(aes(x = name, fill = name)) +
  geom_bar(aes(weight = value),) + 
  labs(x = 'Classifier', y = 'Usage time(s)', 
       title = 'Test Prediction Time') + 
  scale_y_log10() + 
  my_theme
```

#### Test time with feature extraction

```{r}
#plot the test time with feature extraction
tm.test.with %>% pivot_longer(1:ncol(tm.test.with)) %>% 
  ggplot(aes(x = name, fill = name)) +
  geom_bar(aes(weight = value),) + 
  scale_y_log10() + 
  labs(x = 'Classifier', y = 'Usage time(s)', 
       title = 'Feature Extraction and Test Prediction Time') + 
  my_theme
```

## Reference

- Du, S., Tao, Y., & Martinez, A. M. (2014). Compound facial expressions of emotion. Proceedings of the National Academy of Sciences, 111(15), E1454-E1462.

- Cross-Validation on Xgboost, Fall2019 Project3 Section2 Group5. 

